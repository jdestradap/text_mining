{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, expr, when, concat, lit, isnan\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.124:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x110909b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"news.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "| id|id_news|               title|   publication|              author|      date|  year|month| url|             content|\n",
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "|  0|  17283|House Republicans...|New York Times|          Carl Hulse|2016-12-31|2016.0| 12.0|null|WASHINGTON  —   C...|\n",
      "|  1|  17284|Rift Between Offi...|New York Times|Benjamin Mueller ...|2017-06-19|2017.0|  6.0|null|After the bullet ...|\n",
      "|  2|  17285|Tyrus Wong, ‘Bamb...|New York Times|        Margalit Fox|2017-01-06|2017.0|  1.0|null|When Walt Disney’...|\n",
      "|  3|  17286|Among Deaths in 2...|New York Times|    William McDonald|2017-04-10|2017.0|  4.0|null|Death may be the ...|\n",
      "|  4|  17287|Kim Jong-un Says ...|New York Times|       Choe Sang-Hun|2017-01-02|2017.0|  1.0|null|SEOUL, South Kore...|\n",
      "|  5|  17288|Sick With a Cold,...|New York Times|         Sewell Chan|2017-01-02|2017.0|  1.0|null|LONDON  —   Queen...|\n",
      "|  6|  17289|Taiwan’s Presiden...|New York Times| Javier C. Hernández|2017-01-02|2017.0|  1.0|null|BEIJING  —   Pres...|\n",
      "|  7|  17290|After ‘The Bigges...|New York Times|         Gina Kolata|2017-02-08|2017.0|  2.0|null|Danny Cahill stoo...|\n",
      "|  8|  17291|First, a Mixtape....|New York Times|    Katherine Rosman|2016-12-31|2016.0| 12.0|null|Just how   is Hil...|\n",
      "|  9|  17292|Calling on Angels...|New York Times|         Andy Newman|2016-12-31|2016.0| 12.0|null|Angels are everyw...|\n",
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlDF = spark.sql(\"SELECT * FROM data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    " \n",
    "stop_words_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.write.parquet(\"csv_to_paraquet_topics\")\n",
    "df_1 = spark.read.option(\"header\",\"true\").parquet(\"csv_to_paraquet_topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- id_news: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- publication: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= df_1.fillna({'content': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+-----------+-------------+----------+------+-----+----+--------------------+---+\n",
      "|   id|id_news|               title|publication|       author|      date|  year|month| url|             content|uid|\n",
      "+-----+-------+--------------------+-----------+-------------+----------+------+-----+----+--------------------+---+\n",
      "|41272|  60149|Dashcam video app...|        CNN| Kevin Conlon|2016-12-30|2016.0| 12.0|null| (CNN) A newly re...|  0|\n",
      "|41273|  60150|Syria civil war: ...|        CNN| Angela Dewan|2016-12-29|2016.0| 12.0|null|Istanbul (CNN)  S...|  1|\n",
      "|41274|  60151|Ex-cop’s retrial ...|        CNN|         null|2016-12-30|2016.0| 12.0|null| (CNN) A former p...|  2|\n",
      "|41275|  60152|Israel risks slid...|        CNN|         null|2016-12-30|2016.0| 12.0|null| (CNN) Israel, an...|  3|\n",
      "|41276|  60153|Does Melania Trum...|        CNN|         null|2016-12-29|2016.0| 12.0|null| (CNN) During the...|  4|\n",
      "|41277|  60154|Conway wonders if...|        CNN|Daniella Diaz|2016-12-29|2016.0| 12.0|null|Washington (CNN) ...|  5|\n",
      "|41278|  60155|Nevada’s Heller s...|        CNN|Deirdre Walsh|2016-12-29|2016.0| 12.0|null|Washington (CNN) ...|  6|\n",
      "|41280|  60157|US aware of recen...|        CNN|Barbara Starr|2016-12-29|2016.0| 12.0|null| (CNN) After mont...|  7|\n",
      "|41281|  60158|2016’s most visua...|        CNN|         null|2016-12-29|2016.0| 12.0|null| (CNN) 2016 was a...|  8|\n",
      "|41282|  60159|Did Carrie Fisher...|        CNN|         null|2016-12-29|2016.0| 12.0|null| (CNN) It’s a rem...|  9|\n",
      "+-----+-------+--------------------+-----------+-------------+----------+------+-----+----+--------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', 'string')\n",
      "('id_news', 'string')\n",
      "('title', 'string')\n",
      "('publication', 'string')\n",
      "('author', 'string')\n",
      "('date', 'string')\n",
      "('year', 'string')\n",
      "('month', 'string')\n",
      "('url', 'string')\n",
      "('content', 'string')\n",
      "('uid', 'bigint')\n"
     ]
    }
   ],
   "source": [
    "for type in df_1.dtypes:\n",
    "    print(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(record):\n",
    "    content   = record[9]\n",
    "    uid   = record[10]\n",
    "    words = content.split()\n",
    "    # Default list of Stopwords\n",
    "    stopwords_core = ['a', u'about', u'above', u'after', u'again', u'against', u'all', u'am', u'an', u'and', u'any', u'are', u'arent', u'as', u'at', \n",
    "    u'be', u'because', u'been', u'before', u'being', u'below', u'between', u'both', u'but', u'by', \n",
    "    u'can', 'cant', 'come', u'could', 'couldnt', \n",
    "    u'd', u'did', u'didn', u'do', u'does', u'doesnt', u'doing', u'dont', u'down', u'during', \n",
    "    u'each', \n",
    "    u'few', 'finally', u'for', u'from', u'further', \n",
    "    u'had', u'hadnt', u'has', u'hasnt', u'have', u'havent', u'having', u'he', u'her', u'here', u'hers', u'herself', u'him', u'himself', u'his', u'how', \n",
    "    u'i', u'if', u'in', u'into', u'is', u'isnt', u'it', u'its', u'itself', \n",
    "    u'just', \n",
    "    u'll', \n",
    "    u'm', u'me', u'might', u'more', u'most', u'must', u'my', u'myself', \n",
    "    u'no', u'nor', u'not', u'now', \n",
    "    u'o', u'of', u'off', u'on', u'once', u'only', u'or', u'other', u'our', u'ours', u'ourselves', u'out', u'over', u'own', \n",
    "    u'r', u're', \n",
    "    u's', 'said', u'same', u'she', u'should', u'shouldnt', u'so', u'some', u'such', \n",
    "    u't', u'than', u'that', 'thats', u'the', u'their', u'theirs', u'them', u'themselves', u'then', u'there', u'these', u'they', u'this', u'those', u'through', u'to', u'too', \n",
    "    u'under', u'until', u'up', \n",
    "    u'very', \n",
    "    u'was', u'wasnt', u'we', u'were', u'werent', u'what', u'when', u'where', u'which', u'while', u'who', u'whom', u'why', u'will', u'with', u'wont', u'would', \n",
    "    u'y', u'you', u'your', u'yours', u'yourself', u'yourselves']\n",
    "    \n",
    "    # Custom List of Stopwords - Add your own here\n",
    "    stopwords_custom = ['']\n",
    "    stopwords = stopwords_core + stopwords_custom\n",
    "    stopwords = [word.lower() for word in stopwords]    \n",
    "    \n",
    "    text_out = [re.sub('[^a-zA-Z0-9]','',word) for word in words]                                       # Remove special characters\n",
    "    text_out = [word.lower() for word in text_out if len(word)>2 and word.lower() not in stopwords]     # Remove stopwords and words under X length\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "clean_text = df_1.withColumn(\"words\", udf_cleantext(struct([df_1[x] for x in df_1.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11041cc51fe493a8a2ae9dd22986ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11041cc51fe493a8a2ae9dd22986ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------------------------------------------------------+\n",
      "|topic|topic_desc                                                                                |\n",
      "+-----+------------------------------------------------------------------------------------------+\n",
      "|0    |[trump, percent, people, one, new, says, clinton, like, health, president]                |\n",
      "|1    |[trump, isis, president, clinton, state, people, police, states, government, syria]       |\n",
      "|2    |[percent, trump, billion, company, new, tax, apple, people, china, companies]             |\n",
      "|3    |[trump, people, police, students, says, one, new, school, like, president]                |\n",
      "|4    |[trump, north, people, says, one, korea, like, president, new, clinton]                   |\n",
      "|5    |[trump, people, says, one, like, president, new, time, think, also]                       |\n",
      "|6    |[trump, says, people, one, new, police, like, percent, gun, clinton]                      |\n",
      "|7    |[trump, clinton, people, police, says, one, like, new, sanders, women]                    |\n",
      "|8    |[trump, clinton, republican, trumps, republicans, president, percent, people, says, house]|\n",
      "|9    |[trump, clinton, says, people, one, like, women, new, president, sanders]                 |\n",
      "+-----+------------------------------------------------------------------------------------------++-----+------------------------------------------------------------------------------------------+\n",
      "|topic|topic_desc                                                                                |\n",
      "+-----+------------------------------------------------------------------------------------------+\n",
      "|0    |[trump, percent, people, one, new, says, clinton, like, health, president]                |\n",
      "|1    |[trump, isis, president, clinton, state, people, police, states, government, syria]       |\n",
      "|2    |[percent, trump, billion, company, new, tax, apple, people, china, companies]             |\n",
      "|3    |[trump, people, police, students, says, one, new, school, like, president]                |\n",
      "|4    |[trump, north, people, says, one, korea, like, president, new, clinton]                   |\n",
      "|5    |[trump, people, says, one, like, president, new, time, think, also]                       |\n",
      "|6    |[trump, says, people, one, new, police, like, percent, gun, clinton]                      |\n",
      "|7    |[trump, clinton, people, police, says, one, like, new, sanders, women]                    |\n",
      "|8    |[trump, clinton, republican, trumps, republicans, president, percent, people, says, house]|\n",
      "|9    |[trump, clinton, says, people, one, like, women, new, president, sanders]                 |\n",
      "+-----+------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "lda = LDA(k=10, seed=123, optimizer=\"em\", featuresCol=\"features\")\n",
    "\n",
    "ldamodel = lda.fit(rescaledData)\n",
    "\n",
    "ldatopics = ldamodel.describeTopics()\n",
    "\n",
    "def map_termID_to_Word(termIndices):\n",
    "    words = []\n",
    "    for termID in termIndices:\n",
    "        words.append(vocab_broadcast.value[termID])\n",
    "    \n",
    "    return words\n",
    "\n",
    "udf_map_termID_to_Word = udf(map_termID_to_Word , ArrayType(StringType()))\n",
    "ldatopics_mapped = ldatopics.withColumn(\"topic_desc\", udf_map_termID_to_Word(ldatopics.termIndices))\n",
    "ldatopics_mapped.select(ldatopics_mapped.topic, ldatopics_mapped.topic_desc).show(50,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
